{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the Whisper ASR Model\n",
    "# We'll use a pre-trained Whisper model from Hugging Face.\n",
    "# 'openai/whisper-small' is a good balance between performance and size.\n",
    "# You can choose other models like 'openai/whisper-tiny', 'openai/whisper-base',\n",
    "# 'openai/whisper-medium', or 'openai/whisper-large' based on your needs\n",
    "# for accuracy and computational resources.\n",
    "# For English-only transcription, you can use 'openai/whisper-small.en'\n",
    "# which is generally faster and slightly more accurate for English.\n",
    "try:\n",
    "    asr_pipeline = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-small\")\n",
    "    print(\"Whisper model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Whisper model: {e}\")\n",
    "    print(\"Please ensure you have an active internet connection and sufficient disk space.\")\n",
    "    # Fallback or exit if model loading fails\n",
    "    asr_pipeline = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(audio_input):\n",
    "    \"\"\"\n",
    "    Transcribes the input audio (microphone or file) to text using the Whisper model.\n",
    "\n",
    "    Args:\n",
    "        audio_input: This will be the file path to the recorded/uploaded audio\n",
    "                     provided by Gradio's gr.Audio(type=\"filepath\").\n",
    "\n",
    "    Returns:\n",
    "        A string containing the transcribed text, or an error message.\n",
    "    \"\"\"\n",
    "    if asr_pipeline is None:\n",
    "        return \"Error: ASR model failed to load. Cannot transcribe.\"\n",
    "\n",
    "    if audio_input is None:\n",
    "        return \"No audio input provided. Please record or upload an audio file.\"\n",
    "\n",
    "    # The audio_input will be a filepath when type=\"filepath\" is used in gr.Audio.\n",
    "    # The pipeline handles loading the audio from the filepath, resampling, etc.\n",
    "    try:\n",
    "        # Perform the transcription\n",
    "        # You can add generate_kwargs like 'task=\"transcribe\"' and 'language=\"english\"'\n",
    "        # for more control, especially with multilingual models.\n",
    "        transcription_result = asr_pipeline(audio_input)\n",
    "\n",
    "        # The result is a dictionary, and the transcribed text is under the 'text' key.\n",
    "        transcribed_text = transcription_result.get(\"text\", \"Transcription failed.\")\n",
    "\n",
    "        # Clean up the temporary audio file generated by Gradio\n",
    "        if os.path.exists(audio_input):\n",
    "            os.remove(audio_input)\n",
    "            print(f\"Removed temporary audio file: {audio_input}\")\n",
    "\n",
    "        return transcribed_text\n",
    "\n",
    "    except Exception as e:\n",
    "        # Catch any errors during transcription (e.g., corrupted file, model issues)\n",
    "        print(f\"Error during transcription: {e}\")\n",
    "        return f\"An error occurred during transcription: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create the Gradio Interface\n",
    "# We'll define the input and output components for our Gradio app.\n",
    "# gr.Audio: Allows users to record audio via microphone or upload an audio file.\n",
    "#           Setting type=\"filepath\" makes the function receive a temporary file path.\n",
    "# gr.Textbox: Displays the transcribed text.\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=transcribe_audio,\n",
    "    inputs=gr.Audio(\n",
    "        sources=[\"microphone\", \"upload\"], # Allow both microphone recording and file upload\n",
    "        type=\"filepath\",                 # Input will be a path to a temporary audio file\n",
    "        label=\"Input Audio (Record or Upload)\"\n",
    "    ),\n",
    "    outputs=gr.Textbox(label=\"Transcribed Text\"),\n",
    "    title=\"üéôÔ∏è Audio-to-Text Transcriber with Whisper\",\n",
    "    description=\"Record audio using your microphone or upload an audio file to get it transcribed into text using an open-source Whisper ASR model.\",\n",
    "    live=False,  # Set to True for real-time transcription as you speak (more complex to implement properly)\n",
    "                 # For simplicity, we'll process the audio after recording/uploading is complete.\n",
    "    allow_flagging=\"auto\", # Allows users to flag examples, which can be useful for debugging\n",
    "    examples=[\n",
    "        # Example audio files (you'll need to provide actual paths or URLs if using)\n",
    "        # For a basic example, we'll just show the component\n",
    "    ],\n",
    "    # You can add custom CSS for styling\n",
    "    css=\"\"\"\n",
    "    body { font-family: 'Inter', sans-serif; background-color: #f0f4f8; }\n",
    "    .gradio-container { max-width: 800px; margin: 30px auto; padding: 20px; border-radius: 12px; box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1); background-color: #ffffff; }\n",
    "    h1 { color: #2c3e50; text-align: center; margin-bottom: 20px; }\n",
    "    p { color: #34495e; text-align: center; margin-bottom: 30px; }\n",
    "    .gr-button { background-color: #3498db; color: white; border-radius: 8px; padding: 10px 20px; font-size: 16px; transition: background-color 0.3s ease; }\n",
    "    .gr-button:hover { background-color: #2980b9; }\n",
    "    .gr-audio-input, .gr-textbox { border-radius: 8px; border: 1px solid #ccc; padding: 10px; margin-bottom: 15px; }\n",
    "    .gr-audio-input audio { border-radius: 8px; }\n",
    "    \"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Launch the Gradio App\n",
    "# This will start the web server and open the app in your browser.\n",
    "if __name__ == \"__main__\":\n",
    "    iface.launch(share=True) # share=True generates a public link (valid for 72 hours)\n",
    "                             # for easy sharing, useful for testing.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
